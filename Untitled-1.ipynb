{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Kafka'dan gelen veriyi işleme\u001b[39;00m\n\u001b[1;32m     19\u001b[0m query \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselectExpr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAST(key AS STRING)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAST(value AS STRING)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;241m.\u001b[39mwriteStream \\\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;241m.\u001b[39moutputMode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsole\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 25\u001b[0m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/streaming.py:107\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaSparkStreaming\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2\") \\\n",
    "    .config(\"auto.offset.reset\", \"earliest\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"logs_topic\") \\\n",
    "    .load()\n",
    "\n",
    "# Kafka'dan gelen veriyi işleme\n",
    "query = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\") \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting confluent_kafka\n",
      "  Downloading confluent_kafka-2.5.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (2.3 kB)\n",
      "Downloading confluent_kafka-2.5.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: confluent_kafka\n",
      "Successfully installed confluent_kafka-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install confluent_kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:10.820Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"input\":{\"type\":\"log\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\"},\"ecs\":{\"version\":\"1.11.0\"},\"log\":{\"offset\":142510,\"file\":{\"path\":\"/kafka_logs/controller.log\"}},\"message\":\"[2024-08-04 04:58:03,375] INFO [Controller id=0] Processing automatic preferred replica leader election (kafka.controller.KafkaController)\"}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:10.820Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"message\":\"[2024-08-04 04:58:03,375] TRACE [Controller id=0] Checking need to trigger auto leader balancing (kafka.controller.KafkaController)\",\"log\":{\"file\":{\"path\":\"/kafka_logs/controller.log\"},\"offset\":142649},\"input\":{\"type\":\"log\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:10.820Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"message\":\"[2024-08-04 04:58:03,377] TRACE [Controller id=0] Found 0 topic partitions without preferred leader 0 (kafka.controller.KafkaController)\",\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\"},\"log\":{\"offset\":142781,\"file\":{\"path\":\"/kafka_logs/controller.log\"}}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:10.820Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"log\":{\"file\":{\"path\":\"/kafka_logs/controller.log\"},\"offset\":142918},\"message\":\"[2024-08-04 04:58:03,377] TRACE [Controller id=0] Leader imbalance ratio for broker 0 is 0.0 (kafka.controller.KafkaController)\"}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:12.169Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"message\":\"[2024-08-04 04:58:10,826] INFO [MergedLog partition=_confluent-ksql-default_query_CTAS_ERROR_COUNT_TABLE_35-Aggregate-GroupBy-repartition-0, dir=/tmp/confluent.306749/kafka/data] Incrementing merged log start offset to 3443 due to client delete records request (kafka.log.MergedLog)\",\"log\":{\"file\":{\"path\":\"/kafka_logs/server.log\"},\"offset\":3490029},\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"message\":\"2024-08-04T04:58:12.219+0000: 618.796: [GC pause (G1 Evacuation Pause) (young), 0.0198565 secs]\",\"log\":{\"offset\":179355,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"message\":\"   [Parallel Time: 18.5 ms, GC Workers: 4]\",\"input\":{\"type\":\"log\"},\"agent\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"log\":{\"offset\":179451,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"log\":{\"offset\":179494,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"      [GC Worker Start (ms): Min: 618796.6, Avg: 618796.6, Max: 618796.7, Diff: 0.0]\",\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"log\":{\"offset\":179579,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"      [Ext Root Scanning (ms): Min: 1.2, Avg: 1.5, Max: 2.2, Diff: 1.0, Sum: 6.0]\",\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"log\":{\"offset\":179661,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"      [Update RS (ms): Min: 1.8, Avg: 2.3, Max: 2.5, Diff: 0.7, Sum: 9.1]\",\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"log\":{\"offset\":179735,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\"},\"message\":\"         [Processed Buffers: Min: 9, Avg: 17.2, Max: 29, Diff: 20, Sum: 69]\"}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"log\":{\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"},\"offset\":179811},\"message\":\"      [Scan RS (ms): Min: 8.3, Avg: 8.4, Max: 8.5, Diff: 0.2, Sum: 33.8]\",\"input\":{\"type\":\"log\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\"},\"ecs\":{\"version\":\"1.11.0\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"ecs\":{\"version\":\"1.11.0\"},\"log\":{\"offset\":179884,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"      [Code Root Scanning (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\",\"input\":{\"type\":\"log\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"log\":{\"offset\":179967,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"      [Object Copy (ms): Min: 6.0, Avg: 6.1, Max: 6.1, Diff: 0.1, Sum: 24.4]\",\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\"},\"log\":{\"offset\":180044,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"      [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\",\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"message\":\"         [Termination Attempts: Min: 1, Avg: 2.0, Max: 4, Diff: 3, Sum: 8]\",\"input\":{\"type\":\"log\"},\"agent\":{\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"log\":{\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"},\"offset\":180120}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"log\":{\"offset\":180195,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"      [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0]\",\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"log\":{\"offset\":180275,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"      [GC Worker Total (ms): Min: 18.3, Avg: 18.3, Max: 18.4, Diff: 0.0, Sum: 73.3]\",\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"message\":\"      [GC Worker End (ms): Min: 618815.0, Avg: 618815.0, Max: 618815.0, Diff: 0.0]\",\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"log\":{\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"},\"offset\":180359}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"message\":\"   [Code Root Fixup: 0.0 ms]\",\"input\":{\"type\":\"log\"},\"agent\":{\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"log\":{\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"},\"offset\":180442}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"agent\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\"},\"ecs\":{\"version\":\"1.11.0\"},\"log\":{\"offset\":180471,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"   [Code Root Purge: 0.0 ms]\",\"input\":{\"type\":\"log\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"log\":{\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"},\"offset\":180500},\"message\":\"   [Clear CT: 0.1 ms]\",\"input\":{\"type\":\"log\"},\"agent\":{\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\"},\"log\":{\"offset\":180522,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"   [Other: 1.3 ms]\",\"input\":{\"type\":\"log\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"log\":{\"offset\":180541,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"      [Choose CSet: 0.0 ms]\",\"input\":{\"type\":\"log\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\"},\"ecs\":{\"version\":\"1.11.0\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"log\":{\"offset\":180569,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"      [Ref Proc: 0.6 ms]\",\"input\":{\"type\":\"log\"},\"agent\":{\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\"},\"ecs\":{\"version\":\"1.11.0\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"log\":{\"offset\":180594,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"      [Ref Enq: 0.0 ms]\",\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"log\":{\"offset\":180618,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"      [Redirty Cards: 0.3 ms]\",\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"log\":{\"offset\":180648,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"      [Humongous Register: 0.0 ms]\",\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"message\":\"      [Humongous Reclaim: 0.0 ms]\",\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"log\":{\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"},\"offset\":180683}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"input\":{\"type\":\"log\"},\"ecs\":{\"version\":\"1.11.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\"},\"message\":\"      [Free CSet: 0.1 ms]\",\"log\":{\"offset\":180717,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"ecs\":{\"version\":\"1.11.0\"},\"log\":{\"offset\":180743,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\"   [Eden: 46080.0K(46080.0K)->0.0B(47104.0K) Survivors: 6144.0K->5120.0K Heap: 337.0M(1024.0M)->292.7M(1024.0M)]\",\"input\":{\"type\":\"log\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"}}\n",
      "Received message: {\"@timestamp\":\"2024-08-04T04:58:13.027Z\",\"@metadata\":{\"beat\":\"filebeat\",\"type\":\"_doc\",\"version\":\"7.15.0\"},\"host\":{\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"agent\":{\"ephemeral_id\":\"a6242638-5a47-4752-bc16-be9dfd80f273\",\"id\":\"372e3c8c-f088-4782-b9a8-65beb18740c6\",\"name\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\",\"type\":\"filebeat\",\"version\":\"7.15.0\",\"hostname\":\"instance-20240216-1350-bunyamin-dev-confluent-7-4-3\"},\"ecs\":{\"version\":\"1.11.0\"},\"log\":{\"offset\":180856,\"file\":{\"path\":\"/kafka_logs/kafkaServer-gc.log.0.current\"}},\"message\":\" [Times: user=0.07 sys=0.00, real=0.02 secs] \",\"input\":{\"type\":\"log\"}}\n"
     ]
    }
   ],
   "source": [
    "from confluent_kafka import Consumer, KafkaError\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Spark Session oluşturma\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ConfluentKafkaSparkStreaming\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Confluent Kafka Consumer yapılandırması\n",
    "conf = {\n",
    "    'bootstrap.servers': 'localhost:9092',\n",
    "    'group.id': 'my-consumer-group',\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}\n",
    "\n",
    "# Confluent Kafka Consumer oluşturma\n",
    "consumer = Consumer(conf)\n",
    "\n",
    "# Abone olunacak topic\n",
    "topic = 'logs_topic'\n",
    "consumer.subscribe([topic])\n",
    "\n",
    "# Veri okuma ve işleme fonksiyonu\n",
    "def read_from_kafka():\n",
    "    while True:\n",
    "        msg = consumer.poll(1.0)\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                continue\n",
    "            else:\n",
    "                print(msg.error())\n",
    "                break\n",
    "\n",
    "        # Mesajı işleme\n",
    "        print('Received message: {}'.format(msg.value().decode('utf-8')))\n",
    "\n",
    "        # Burada, okunan veriyi Spark DataFrame'e dönüştürüp işleyebilirsiniz\n",
    "        # Örnek:\n",
    "        # df = spark.createDataFrame([(msg.value().decode('utf-8'),)], ['value'])\n",
    "        # df.show()\n",
    "\n",
    "# Kafka'dan okuma işlemini başlatma\n",
    "try:\n",
    "    read_from_kafka()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "finally:\n",
    "    # Consumer'ı kapatma\n",
    "    consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SparkSession' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241m.\u001b[39mbuilder \\\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKafkaSparkStreaming\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.jars.packages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.driver.memory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4g\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspark.executor.memory\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4g\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SparkSession' is not defined"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaSparkStreaming\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/spark/python/pyspark/sql/utils.py\", line 190, in deco\n",
      "    return f(*a, **kw)\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <exception str() failed>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "Py4JError",
     "evalue": "py4j.reflection.TypeUtil does not exist in the JVM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(111, 'Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Kafka'dan gelen veriyi işleme\u001b[39;00m\n\u001b[1;32m     23\u001b[0m query \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselectExpr(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAST(key AS STRING)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCAST(value AS STRING)\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;241m.\u001b[39mwriteStream \\\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;241m.\u001b[39moutputMode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsole\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 29\u001b[0m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 5 dakika sonra sonlanır\u001b[39;00m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/streaming.py:105\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(timeout, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout must be a positive integer or float. Got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m timeout)\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/utils.py:192\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 192\u001b[0m     converted \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava_exception\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/utils.py:159\u001b[0m, in \u001b[0;36mconvert_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AnalysisException(origin\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_instance_of(gw, e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark.sql.streaming.StreamingQueryException\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStreamingQueryException\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_instance_of(gw, e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark.sql.execution.QueryExecutionException\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m QueryExecutionException(origin\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/utils.py:60\u001b[0m, in \u001b[0;36mCapturedException.__init__\u001b[0;34m(self, desc, stackTrace, cause, origin)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m convert_exception(cause) \u001b[38;5;28;01mif\u001b[39;00m cause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m origin\u001b[38;5;241m.\u001b[39mgetCause() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcause \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetCause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_origin \u001b[38;5;241m=\u001b[39m origin\n",
      "File \u001b[0;32m/opt/spark/python/pyspark/sql/utils.py:158\u001b[0m, in \u001b[0;36mconvert_exception\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_instance_of(gw, e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark.sql.AnalysisException\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m AnalysisException(origin\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mis_instance_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morg.apache.spark.sql.streaming.StreamingQueryException\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StreamingQueryException(origin\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_instance_of(gw, e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark.sql.execution.QueryExecutionException\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py:464\u001b[0m, in \u001b[0;36mis_instance_of\u001b[0;34m(gateway, java_object, java_class)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    462\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjava_class must be a string, a JavaClass, or a JavaObject\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgateway\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpy4j\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreflection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTypeUtil\u001b[49m\u001b[38;5;241m.\u001b[39misInstanceOf(\n\u001b[1;32m    465\u001b[0m     param, java_object)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py:1661\u001b[0m, in \u001b[0;36mJavaPackage.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m JavaClass(\n\u001b[1;32m   1659\u001b[0m         answer[proto\u001b[38;5;241m.\u001b[39mCLASS_FQN_START:], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client)\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m does not exist in the JVM\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(new_fqn))\n",
      "\u001b[0;31mPy4JError\u001b[0m: py4j.reflection.TypeUtil does not exist in the JVM"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaSparkStreaming\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.2\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"logs_topic\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "# Kafka'dan gelen veriyi işleme\n",
    "query = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\") \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination(timeout=30)  # 5 dakika sonra sonlanır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.0\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaSparkStreamingTest\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"logs_topic\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "query = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\") \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination(60)  # 60 saniye boyunca çalışır"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
